# GEO Classification ğŸ§¬ğŸ¤–
Implementation of a pipeline to compare the performance of Machine Learning classifiers on Gene Expression Omnibus (GEO) data.
## Quick start
Install Python:

`sudo apt install python3`

Install pip:

`sudo apt install --upgrade python3-pip`

Install requirements:

`python -m pip install --requirement requirements.txt`

### Step 1
Run the script `preprocess.py` to read, preprocess and save data into a `.pkl` or `.csv` file from a GEO matrix series file.
```
python preprocess.py [-h] --txt-path TXT-PATH [--csv-path CSV-PATH] 
                        --pkl-path PKL-PATH --target-header TARGET-HEADER
                        --target-regexs TARGET-REGEXS [TARGET-REGEXS ...]
                        --new-targets NEW-TARGETS [NEW-TARGETS ...]
                        [--noise NOISE] [--log-transform | --no-log-transform]
                        [--std-samples | --no-std-samples]
```
| Argument | Optional | Description    |
| -------- | -------- | -------------- |
| -h, --help | âœ”ï¸ | Show the help message and exit. |
| --txt-path TXT-PATH | | Path to the series matrix file. |
| --csv-path CSV-PATH | âœ”ï¸ | Path to the `.csv` file to create. |
| --pkl-path PKL-PATH | | Path to the `.pkl` file to create (a serialized dictionary with the following keys: 'X', 'y', 'features_ids', 'samples_ids'). |
| --target-header TARGET-HEADER | | Header that identifies targets; WARNING: if there are multiple lines with the same header the first line will be used. |
| --target-regexs TARGET-REGEXS [TARGET-REGEXS ...] | | Regular expression to select samples by their target.
| --new-targets NEW-TARGETS [NEW-TARGETS ...] | | Targets to use instead. |
| --noise NOISE | âœ”ï¸ | Percentage of gaussian noise to add (default: 0). |
| --log-transform, --no-log-transform | âœ”ï¸ | Whether to apply a logarithimc transformation (default: False). |
| --std-samples, --no-std-samples | âœ”ï¸ | Whether to standardize samples (default: False). |
### Step 1.2 (optional)
Run the script `integrate.py` to merge preprocessed datasets into a single one or to delete from them features that are not shared by all.
```
python integrate.py [-h] --pkl-in PKL-IN [PKL-IN ...] --pkl-out PKL-OUT [PKL-OUT ...]
                    [--csv-out CSV-OUT [CSV-OUT ...]]
```
| Argument | Optional | Description    |
| -------- | -------- | -------------- |
| -h, --help | âœ”ï¸ | Show the help message and exit. |
| --pkl-in PKL-IN [PKL-IN ...] | | List of `.pkl` files to integrate. |
| --pkl-out PKL-OUT [PKL-OUT ...] | | Path to the `.pkl` file/s to create. If a single path is passed, datasets will be merged, otherwise new datasets will be created with the only features they all share. |
| --csv-out CSV-OUT [CSV-OUT ...] | âœ”ï¸ | Path to the `.csv` file/s to create. If a single path is passed, datasets will be merged, otherwise new datasets will be created with the only features they all share. |

### Step 2
Run the script `compare.py` to compare the performances of ML classifiers on preprocessed datasets.
You can choose to compare the following classifiers: [Nearest Centroid](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html) (NC), [K-Nearest Neighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) (KNN),
[Support Vector Machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) (SVM), [Gaussian Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) (GNB), [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) (RF), [Rank Aggregation Classifier](https://github.com/iretes/RAC) (RAC).

The table below shows the hyperparameters that will be explored.
| Classifier | Hyperparameter    | Values                                                 |
| ---------- | ----------------- | ------------------------------------------------------ |
| ğŸŸ¥ NC      | `metric`            | `'euclidean', 'manhattan'`                           |
| ğŸŸ§ KNN     | `weights`           | `'uniform', 'distance'`                              |
| ğŸŸ§ KNN     | `n_neighbors`       | `range(3, max_neighbors+1, 2)`<sup>1</sup>           |
| ğŸŸ¨ SVM     | `C`                 | `0.001, 0.1, 1, 100`                                 |
| ğŸŸ¨ SVM     | `kernel`            | `'linear', 'poly', 'rbf', 'sigmoid'`                 |
| ğŸŸ¨ SVM     | `degree`            | `2, 3, 4`                                            |
| ğŸŸ¨ SVM     | `gamma`             | `'scale', 'auto', 0.001, 0.1, 1, 100`                |
| ğŸŸ© GNB     | `var_smoothing`     | `1e-9, 1e-3, 1e-1, 0.5`                              |
| ğŸŸ¦ RF      | `n_estimators`      | `50, 100, 500`                                       |
| ğŸŸ¦ RF      | `min_samples_split` | `0.1, 0.25, 0.33, 2`                                 |
| ğŸŸª RAC     | `r_method`          | `'average', 'min', 'max'`                            |
| ğŸŸª RAC     | `ra_method`         | `'borda', 'borda_median', 'borda_gmean', 'borda_l2'` |
| ğŸŸª RAC     | `metric`            | `'spearman', 'kendall'`                              |
| ğŸŸª RAC     | `weighted`          | `True, False, (1/3*n_feature, 1/3*n_feature)`        |
| ğŸŸª RAC     | `p`                 | `1, 2, 3/4`                                          |

<sup>1</sup> max_neighbors is equal to the dimension of the training fold divided by the number of classes if such quantity is less than 20, otherwise it is equal to 20.

The performances of each classifiers will be evaluated by computing the following scores: [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score), [f1 micro](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score), [f1 macro](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score), [f1 weighted](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score), [AUROC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score), [AUROC weighted](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score).
Scores will be computed either averaging their values over the test folds, or on the concatenation of predictions made for each test fold.
Results will be saved in `.csv` files.
Predictions made by classifiers will be serialized in the file `predictions.pkl`, to access them
see the script `read_predictions.py`.
```
python compare.py [-h] [--nested-cv | --no-nested-cv] --dev-dataset DEV-DATASET
                    [--test-dataset TEST-DATASET] [--pos-lbl POS-LBL]
                    --output-path OUTPUT-PATH
                    [--classifiers CLASSIFIERS [CLASSIFIERS ...]]
                    [--best-score BEST-SCORE] [--n-splits N-SPLITS] 
                    [--ext-n-splits EXT-N-SPLITS] [--loo | --no-loo]
                    [--ext-loo | --no-ext-loo]
                    [--random-state RANDOM-STATE] [--standardize | --no-standardize]
                    [--verbose | --no-verbose]
```
| Argument | Optional | Description    |
| -------- | -------- | -------------- |
| -h, --help | âœ”ï¸ | Show the help message and exit. |
|--nested-cv, --no-nested_cv | âœ”ï¸ | Whether to perform nested cross validation (default: False). |
|--dev-dataset DEV-DATASET | | Path to the development dataset. |
| --test-dataset TEST-DATASET | âœ”ï¸ | Path to the test dataset. |
| --pos-lbl POS-LBL | âœ”ï¸ | Label of the 'positive' class in binary classification. |
| --output-path OUTPUT-PATH | | Path where to save results. |
| --classifiers CLASSIFIERS [CLASSIFIERS ...] | âœ”ï¸ | Classifiers to compare, must be in ['RAC', 'NC', 'KNN', 'SVM', 'GNB', 'RF']. If not specified all the classifiers will be compared. |
| --best-score BEST-SCORE | âœ”ï¸ | Scorer function to use to determine the best parameters, must be in ['accuracy', 'mean accuracy', 'concat accuracy', 'f1 micro', 'mean f1 micro', 'concat f1 micro', 'f1 macro', 'mean f1 macro', 'concat f1 macro', 'f1 weighted', 'mean f1 weighted', 'concat f1 weighted', 'aggregated rank']. If not specified all the scores will be evaluated.
| --n-splits N-SPLITS | âœ”ï¸ | Number of folds to use; with --nested_cv refers to the number of internal folds; ignored with --loo (default: 5). |
| --ext-n-splits EXT-N-SPLITS | âœ”ï¸ | Number of folds to use in the external cross validation; ignored with --ext-loo (default: 5). |
| --loo, --no-loo | âœ”ï¸ | Whether to perform leave one out cross validation; with --nested_cv leave one out cross validation will be done in the internal cross validation (default: False). |
| --ext-loo, --no-ext-loo | âœ”ï¸ | Whether to perform leave one out cross validation in the external cross validation (default: False).
| --random-state RANDOM-STATE | âœ”ï¸ | Seed to get reproducible results. |
| --standardize, --no-standardize | âœ”ï¸ | Whether to standardize features (default: False). |
| --verbose, --no-verbose | âœ”ï¸ | Whether to print verbose output (default: False). |

## Usage example
See file `run_pipeline.sh`.